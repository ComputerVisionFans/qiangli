<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="Qiang"> 
<meta name="description" content="Academic homepage of Qiang Li">
<link href="files/main.css" media="all" rel="stylesheet">
<title>Qiang Li's Homepage</title>
</head>
	
<body>
	<table border="0" id="information" width="100%">
		<tbody>
			<tr>
				<td >
					<p align="center"><font face="Arial"><img border="0" src="imgs/IMG_7230.JPG" height="260"></font></p>
				</td>
				<td>
					<font face="Arial" size="5"><b>&nbsp;Qiang Li <span lang="zh-cn">(利 强)</span></b></font>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; M.Sc. Computer Science </font></p>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; RWTH Aachen University, Aachen, Germany</font></p>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; Email: qiang.li@rwth-aachen.de</font></p>
					&nbsp; <a href="files/CV_Lebenslauf_QiangLi.pdf">CV</a> &bull; <a href="https://www.linkedin.com/in/jonascomputervision/">LinkedIn</a> &bull; <a href="https://github.com/Johnny-liqiang">GitHub</a> &bull; <a href="https://www.semanticscholar.org/author/Qiang-Li/2146263688">Scholar</a> &bull; <a href="https://medium.com/@jonasingermany">Blog</a>
				</td>
			</tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="5">
		About</font></b></p>
	
	<table border="0" width="100%">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 12pt; line-height: 2;">
						Guten Tag! I am currently working as an IT/OT & ML Senior Analyst at Accenture. Prior to joining Accenture, I served as an IDEA Research Grant Student in Prof. Dr. <a href="https://imsb.ethz.ch/people/person-detail.html?persid=139973"> Manfred Claassen </a> Group at ETH Zürich, where I obtained my Master's degree in Computer Science from RWTH Aachen University. I earned my bachelor's degree from HFUT with exceptional academic performance and was awarded four years of national scholarships. During my Bachelor's studies, I specialized in IoT and also founded the HFUT Robocup Lab. After completing my B.Sc., I worked as a computer vision working student at Siemens AG Aachen Gas Turbine Research Center while pursuing my Master's degree in Informatik at RWTH Aachen.<br>
					</font>
					<br>
					<font face="Arial" style="font-size: 12pt; line-height: 2;">My research interests primarily revolve around Object Recognition and Segmentation, the Deployment of ML systems, Model Interpretability, Multi-Tasking and Multi-Modality.</font>
				</td>
			</tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="5"><br>
		News</font></b></p>
		<font face="Arial" style="font-size: 12pt; line-height: 2;">
		<ul>    
			<li><b style="color: red; background-color: #ffff42">NEW</b> [May, 2023] Our work  <b> Self-supervised Learning with Temporary Exact Solutions: Linear Projection </b> has been accepted on <a href="https://2023.ieee-indin.org/keynotes.php"> 21st IEEE  International Conference on Industrial Informatics, INDIN’23</a> See you in 17th - 20th July 2023, Lemgo, Germany!</li>
			<li><b style="color: red; background-color: #ffff42">NEW</b> [Feb, 2023] Our work <b> Exploiting Interactivity and Heterogeneity for Sleep Stage Classification via Heterogeneous Graph Neural Network </b> has been accepted on <a href="https://ieeexplore.ieee.org/abstract/document/10095397"> 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023)</a> as Main Track Full Paper!</li>
			<li> [Jan, 2023] Feel free to check my blog about CI/CD for ML System topics<a href="https://medium.com/twodigits/how-i-get-accepted-on-the-neurips2022-dmml-workshop-challenges-in-deploying-and-monitoring-ml-65249e857db9"> Medium.</a></li>
			<li> [Dec, 2022] Blog on Synthetic Data Generation topics <a href="https://medium.com/@jonasingermany/study-note-one-day-at-neurips-2022-synthetic-data-workshop-66175d8f7c13">Study Note: One Day at (NeurIPS 2022) Synthetic Data Workshop</a></li>
			<li> [Nov, 2022] Promoted to be <b>Senior Analyst</b>! This was an amazing year, with <b>106%</b> average chargeability in real industry projects, <b>6+</b> assets & offerings being demonstrated to the clients, <b>2 publications</b> in ICLR/NeurIPS, Computer Vision Engineer roles, RollOut Team Lead roles, and leading a Community and Relationship sub-circle! </li>
			<li> [Oct, 2022] Our paper <b> Continual learning on deployment pipelines for Machine Learning Systems </b> was accepted to the Challenges in deploying and monitoring ML systems workshop on <b> NeurIPS 2022</b>. Paper will be released on <a href="https://sites.google.com/view/dmmlsys-neurips2022/home">Website</a>, and live stream on <a href="https://nips.cc/virtual/2022/workshop/49982">NeurIPS 2022</a>.</li>
			<li> [April, 2022] Our work <b> Explainable AI: Object Recognition With Help From Background </b> has been accepted by CSS Workshop on <b> ICLR 2022</b>! See us on <a href="https://sites.google.com/view/cssiclr2022/home">workshop website</a> and our live presentation on <a href="https://iclr.cc/virtual/2022/workshop/9069">ICLR</a>.</li>
			<li> [March, 2021] AttentionNet paper has been accepted by AI for Public Health Workshop on <b>ICLR 2021</b>!</li>
			<li> [August, 2020] Defend master thesis <b>Cell Morphology Based Diagnosis of Cancer using CNNs</b> to supervisor: Prof. Dr. <a href="https://imsb.ethz.ch/people/person-detail.html?persid=139973"> Manfred Claassen</a> from IMSB Group ETH Zürich, Prof. Dr. <a href="https://www.vision.rwth-aachen.de/person/1/"> Bastian Leibe</a> from RWTH Aachen, Dr. <a href="https://caim.ee.ethz.ch/news-and-events/news/2018/06/corin-otesteanu-receives-the-young-investigator-travel-award-by-ndi-at-ipcai-2018-germany.html">Corin Otesteanu</a>, PhD CVLab and PostDoc from IMSB Group ETH Zurich. </li>
			
		</ul>
		</font>

	<p><b><font face="Times New Roman" size="5"><br>
	Research Experiences</font></b></p>
	<table border="0"  width="100%">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 12pt;">
					<!--I am broadly interested in designing machine learning systems that can perceive the world as we human do and achieve "science for good" goal. In my exploration of this goal, I have studied and done research in medical image analysis, 3D reconstruction, unsupervised learning, video object perception. I have had the great fortune to participate in several interesting projects with inspiring and talented collaborators.<br>-->
					[<a href="files/Recommendation_Letter_Qiang from ETH Zurich.pdf">Feedback from Mentor at <b>ETH Claassen Lab</b></a>]
					<br>
					<br>
					[<a href="files/Proof of Employment Certificate_PayLuft_Qiang Li.pdf">Feedback from Mentor at <b>PayLuft Zürich Based Fintech Startup</b></a>]
					<br>
					<br>
					<!--I did an internship at Sinovation Venture AI Institute, where I was mainly responsible for NLP Chinese GPT model design based on the pre-trained Huggingface Transformer Model on industry scenarios.<br>-->
					[<a href="files/Recommendation Letter from Sinovation Venture.pdf">Feedback from Mentor at <b>Sinovation Venture AI Institute</b></a>]
					<br>
					<br>	
					<!--Prior to that, I finished a series of lectures, seminar and thesis: computer vision, advanced computer vision (1.7/ 1.0-5.0, the less the better), Schwerpunkte in machine learning (1.7/ 1.0-5.0, the less the better) under the supervision of Professor <a href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>.  Spent a summer internship with <a href="https://hci.rwth-aachen.de/borchers"> Prof. Dr. Jan Borchers </a> in <a href="https://hci.rwth-aachen.de/">HCI and Soft Robot Group</a> (1.3/ 1.0-5.0, the less the better).<br>-->
					[<a href="/files/recommendation letter from RWTH Prof..pdf">Feedback from Mentor at <b>RWTH Computer Vision Group</b></a>]
					<br>
					<br>	
					[<a href="https://www.maschinenmarkt.international/new-paths-in-3d-printing-a-853363/">Feedback & Interview from Mentor at <b>Siemens AG Aachen Gas Turbin Research Center</b></a>]
					<br>	
					
						
				</font></p><font face="Arial" style="font-size: 11pt;"></font>
				</td>
			</tr>
		</tbody>
	</table>


 	<p><b><font face="Times New Roman" size="5"><br>
		Conference & Journal Reviewer Contribution </font></b></p>
		<font face="Arial" style="font-size: 12pt; line-height: 2;">
			<ul>
				<li> Journal：IEEE Open Journal of Signal Processing (OJSP)（1+）</li>
				<li> Conference：ICASSP（9+） </li>
				<li> Review Categories：Computational imaging systems，Machine learning for image and video processing，Pattern recognition and classification，Explainable and interpretable machine learning，Robust and trustworthy machine learning，Self-supervised and semi-supervised learning </li>
			</ul>
		</font>




	
	<p><b><font face="Times New Roman" size="5"><br>
		Honors and Awards</font></b></p>
		<font face="Arial" style="font-size: 12pt; line-height: 2;">
			<ul>
				<li>The Accenture Trained Architecture Foundation (TAF) Program, Certified TTA, 2023.</li>
				<li>The RWTH Stipend in IDEA League Research Grant, ETH Zürich, 2020.</li>
				<li>The DeeCamp2020 by Sinovation Ventures and UNDP, Best Team Leader prize, 2020.</li>
				<li>The DeeCamp2020 by Sinovation Ventures and UNDP, Excellent Performance Team prize, 2020.</li>
				<li>The Siemens Statistic/Six Sigma training, Yellow Belt Certiﬁcation, 2019.</li>
				<li>The Europe BEST Engineering Competition, 2nd Prize Europe region, 2018.</li>
				<li>The Connected Campus Idea Competition (CCIC), Top 7 in Berlin, 2017.</li>
				<li>The Excellent student of Hefei University of Technology, HFUT University, 2016.</li>
				<li>The International Robocup Robot Competition, 1st Prize in China, 12th Prize in Global, 2014.</li>
				<li>The International Internet of Things Innovation,  3rd Prize in China, 2014.</li>
			</ul>
		</font>

	
	<p><b><font face="Times New Roman" size="5"><br>
		Projects and Publications</font></b></p>
	<table width="100%">
		<!-- INDIN 2023 -->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./imgs/linear%20projection-Page-2.drawio%20(1).png" width="280" alt="HPHH" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>Self-supervised Learning with Temporary Exact Solutions: Linear Projection</strong><br>
			Evrim Ozmermer, <strong>Qiang Li</strong> <br>
			Accepted by <em>  IEEE 21st International Conference on Industrial Informatics (<strong>INDIN'23</strong>), Full paper, 2023</em>.<br>
			In this paper, we present a self-supervised learning method for training, not limited to but especially visual transformers that are able to learn meaningful representations of images and videos without requiring large amounts of labeled data. Our method is based on using exact solutions of the representations that the model generates. It is shown that the model is able to learn useful features that can be later fine-tuned on industrial downstream tasks.<br>
			<b> <a href="https://ieeexplore.ieee.org/abstract/document/10217918"> <font color="##808080">Paper</font></a></b>&nbsp;&nbsp;&nbsp;
			<b> <a href="https://github.com/rootvisionai/solo-learn"> <font color="##808080">Code</font></a></b>&nbsp;&nbsp;&nbsp;	
			<b><a href="https://2023.ieee-indin.org/keynotes.php"><font color="#808080">Conference Website</font></a></b>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>
		
		
		
		
		
		<!--NPHH ICASSP2023 -->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./files/FE11E312-9E98-4137-9033-58A7F9356150.jpeg" width="280" alt="HPHH" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>Exploiting Interactivity and Heterogeneity for Sleep Stage Classification via Heterogeneous Graph Neural Network</strong><br>
			Ziyu Jia, Youfang Lin, Yuhan Zhou, Xiyang Cai, Peng Zheng, <strong>Qiang Li</strong>, Jing Wang<br>
			Accepted by <em>  2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (<strong>ICASSP</strong>),Full paper, 2023</em>.<br>
			In this paper, we propose a novel deep model SleepHGNN for sleep stage classification. The Heterogeneous Graph Transformer is applied for capturing the interactivity and heterogeneity of the multimodal signals. To the best of our knowledge, this is the first attempt to leverage heterogeneous graph neural networks for sleep stage classification. Since the SleepHGNN is a universal framework for the graph-level classification task based on the heterogeneous graph, we will generalize model to other domains like protein classification and molecular graph classification including anticancer chemical compound classification in the future.<br>
			<b> <a href="https://ieeexplore.ieee.org/document/10095397"> <font color="##808080">Paper</font></a></b>&nbsp;&nbsp;&nbsp;
			<b> <a href="https://github.com/zhouyh310/SleepHGNN"> <font color="##808080">Code</font></a></b>&nbsp;&nbsp;&nbsp;	
			<b><a href="https://2023.ieeeicassp.org/"><font color="#808080">Conference Website</font></a></b>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>
		
		
		<!--CI/CD Deployment NIPS2022 -->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./imgs/deployment pipeline on NIPS2022.jpg" width="280" alt="CI/CD pipeline" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>Continual learning on deployment pipelines for Machine Learning Systems</strong><br>
			<strong>Qiang Li</strong>, Chongyu Zhang<br>
			Accepted by <em> The Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), DMML Workshop, 2022</em>.<br>
			In this work, we presented a comparison of various solutions for the deployment of machine learning systems, includes different layers of automation from highly manual model training and deployment to an automated continuous integration workflow. We proposed the evaluation metrics in practice and describe how real-world requirements differ from more academic settings.
                        <b><a href="https://nips.cc/virtual/2022/workshop/49982"><font color="##808080">Livestream on NeurIPS2022</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="imgs/Poster.png"><font color="#FF0000">Poster</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://arxiv.org/abs/2212.02659"><font color="##808080">Paper on arxiv</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://www.researchgate.net/publication/366086359_Continual_learning_on_deployment_pipelines_for_Machine_Learning_Systems"><font color="##808080">ResearchGate</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://sites.google.com/view/dmmlsys-neurips2022/home"><font color="#808080">Workshop Website</font></a></b>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>
		
		
		
		
		<!--Background Image-11-->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./imgs/object_classification_with_help _from_backgrounds ICLR workshop.jpg" width="280" alt="ExplainAI" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>Explainable AI: Object Recognition With Help From Background</strong><br>
			Raza Hashmi, <strong>Qiang Li</strong><br>
			Accepted by <em> The International Conference on Learning Representations (<strong>ICLR</strong>), CSS Workshop, 2022</em>.<br>
			This work explores how backgrounds might help in object recognition tasks in depth. Our project is fascinated by the baseline work done by Xiao et al. in their noise or signal paper.
                        <b><a href="https://sites.google.com/view/cssiclr2022/home"><font color="#808080">Website</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://blog.iclr.cc/2022/05/12/reflection-on-the-dei-initiative-at-iclr-2022/"><font color="#808080">Blogs</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://iclr.cc/virtual/2022/workshop/9069"><font color="#FF0000">Camera ready video of presentation on ICLR2022</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://www.kaggle.com/datasets/qianglijonas/imagenet11"><font color="##808080">Dataset on Kaggle (140+ Download!)</font></a></b>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>
		
		
		
		<!--AIQX-->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./imgs/AIQX.JPG" width="280" alt="AttentionNet" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>AI Quality Next - BMW Group - Computer Vision project</strong><br>
						<strong>Computer Vision Engineer: Qiang Li</strong><br>
					AIQX provides a platform to integrate machine learning & deep learning algorithms for visual inspections directly into the production processes. Creation of a central standard for the implementation of AI for quality inspections in the global production system. AI provides far more robust algorithms and opens new areas of defect detection and order verification for manufacturing.<br>
			<b><a href="https://youtu.be/qgZy7Uqt7ok"><font color="#808080">Youtube:Artificial Intelligence at the BMW Group</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://www.youtube.com/watch?v=Fo6pWIi-Ixo"><font color="#808080">Youtube:BMW Factory – Integration of A.I. in the Production Line</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://www.bmwgroup.com/en/news/general/2023/BMWGroupIT.html?tl=soc-link-dabu-brnd-mn-iadn-post-gallerya-01.02.2023-bproadul-c98a00c06a58"><font color="#FF0000">Published materials about our AIQX Project & Usecases in News and Major Media! Won BMW Q-Award*</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://www.cnbc.com/2023/07/21/how-bmw-uses-ai-to-make-vehicle-assembly-more-efficient.html"><font color="#FF0000"> Our AIQX Project & Usecases in CNBC News*</font></a></b>&nbsp;&nbsp;&nbsp;
		</p></td></tr>
		</tbody>

		
		<!--AttentionNet-->
		<tbody><tr>
		<td width="30%" valign="middle"><p><img src="./imgs/37highres.png" width="280" alt="AttentionNet" style="border-style: none" align="top"></p></td>
		<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
			<strong>All You Need Is Cell Attention: A Cell Annotation Tool for Single-Cell Morphology Data</strong><br>
						<strong>Qiang Li</strong>*, Corin Otesteanu, Lily Xu<br>
					Accepted by <em> The International Conference on Learning Representations (<strong>ICLR</strong>), Workshop on AI for Public Health, 2021</em>.<br>
			<b><a href="https://aiforpublichealth.github.io/papers/ICLR-AI4PH_paper_37.pdf"><font color="#FF0000">PDF</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://github.com/Johnny-liqiang/CellNetUML"><font color="##808080">Code/Software </font></a></b>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>

		<!--CellNet software-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/cellnet software.svg" width="280" alt="CellNet" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<strong>Cell Morphology Based Diagnosis of Cancer using Convolutional Neural Networks: CellNet</strong><br>
					<strong>Qiang Li</strong>, Yiran Xing, Tianwei Lan, ChenYu Tian, Ying Chen<br>
				Won Challenge on <em> Medical Track of AI in Public Healthcare of DeeCamp 2020</em>.<br>
				<b><a href="https://www.sinovationventures.com/ai"><font color="#FF0000">Website</font></a></b>&nbsp;&nbsp;&nbsp;
				<b><a href="https://github.com/Johnny-liqiang/CellNetUML"><font color="#FF0000">Code/Models</font></a></b>&nbsp;&nbsp;&nbsp;
				<a href="https://drive.google.com/file/d/1wCXke7iyolk2AkwOOM3Fu1uONrznqUEs/view"><font color="##808080">Video</font></a>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>
		
		<!--CellNet thesis
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/cellnet.png" width="280" alt="CellNet" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<strong>Master thesis: Cell Morphology Based Diagnosis of Cancer using Convolutional Neural Networks: CellNet</strong><br>
					<strong>Qiang Li</strong><br>
				Masterand in <em> ETH Zürich Claassen Lab</em>.<br>
				<b><a href="https://github.com/Johnny-liqiang/CellNetUML"><font color="#FF0000">Code/Models</font></a></b>&nbsp;&nbsp;&nbsp;
				<a href="files/Qiang-Thesis.pdf"><font color="##808080">Slides</font></a>
			</p></td></tr>
		</tbody>
                -->
		

		<!--PCA-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/pca.svg" width="280" alt="PCA" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<strong>Localization and visualization of defects by PCA, KMeans, Colorspace Template Matching for Additive Manufacturing</strong><br>
					 Hamid Jahangir, <strong>Qiang Li</strong><br>
				 Invited Talk on <em>International Conference on Additive Manufacturing (<strong>ICAM</strong>), 2020</em>.<br>
			<b><a href="https://static1.squarespace.com/static/5b2aae84f407b43d00601acb/t/5f7f90fe87c21e4240f19c1d/1602195713464/AMCOE-ICAM-In-Process.pdf"><font color="#FF0000">Invited Talk</font></a></b>&nbsp;&nbsp;&nbsp;
			<b><a href="https://docs.google.com/presentation/d/1Rgljw6_YFpYjUHTBe-qzGymEXjoWSFKVIia3r-r5iO0/edit?usp=sharing "><font color="##808080">Slides</font></a></b>&nbsp;&nbsp;&nbsp;
			<a href="files/An AI software i developed for Siemens.pdf"><font color="##808080">Software</font></a>&nbsp;&nbsp;&nbsp;
			</p></td></tr>
		</tbody>

		

		
		<!--GPT-3 industry survey and its applied project-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/4 E-mail Auto-Replier powered by GPT-2.png" width="280" alt="CFUN" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<strong>GPT-3 industry survey and applied scenarios</strong><br>
				Qiyi Ye, <strong>Qiang Li</strong><br>
				Designed 3 GPT-based generative model on real scenario at <em> Sinovation Ventures AI Institute （创新工场）, 2020</em>.<br>
			<b><a href="https://github.com/Johnny-liqiang/AI-Research-Intern-In-Sinovation-Venture"><font color="#FF0000">Code/GPT generative models</font></a></b>&nbsp;&nbsp;&nbsp;
			<a href="files/Technical report on GPT-3 and its applied Business Scenario.pdf"><font color="##808080">Slides</font></a>
			</p></td></tr>
		</tbody>
	</table>


	<p><b><font face="Times New Roman" size="5"><br>
		Miscellaneous</font></b></p>
		<table border="0" style="border-width: 0px">
			<tbody>
				<tr>
					<td width="30%" valign="middle"><p><img src="./files/redbook.gif" width="280" height ="420" alt="RedBook" style="border-style: none" align="top"></p></td>
					<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 12pt;"> <em> Hobbies: Vloger who loves KPOP, Museum, Cooking... And you can find me in TikTok / Little Red Book(小红书)/ Wechat Channel by ‘Jonas的新鲜感’（Jonas' curiosity), We have received over millions of views and likes 👍, and 2.5+ thousands of followers! Have created 100+ Vlogs. Keeping Learning! Let's move on together!<br>
						I am a fan of Hackathons. It gave me valuable experiences, developed critical thinking, problem-solving, and leadership skills.<br> </em>
						<br>
					</font></p><font face="Arial" style="font-size: 11pt;"></font>
					</td>
				</tr>
			</tbody>
		</table><br><br>
	
	
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
	<span id="busuanzi_value_page_pv" style="color:#000"> <i class="fa fa-spinner fa-spin"></i></span>
	<br><br><br>

	<hr>
	<font style="font-size:10">Qiang Li<i> Last updated: 31. Oct, 2023</i></font>

</body>
